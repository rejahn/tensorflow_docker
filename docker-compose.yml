version: '3.8'

services:
  tensorflow_gpu:
    build:
      context: .
      dockerfile: Dockerfile
    image: tensorflow_gpu_test
    command: bash
    tty: true
    ports:
      - 8082:8888
    volumes: [] # if you have any volumes to mount
    working_dir: /user
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [gpu]
